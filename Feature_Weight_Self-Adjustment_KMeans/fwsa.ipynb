{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from fwsa_utils import u_calculation\n",
    "from fwsa_utils import fwsa_cost_function\n",
    "from fwsa_utils import update_Z\n",
    "from fwsa_utils import fwsa_weight_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwsa(X, k):\n",
    "    \"\"\"Put data (X) in k clusters based on the weight of each feature \n",
    "    which is going to be calculated based on X\n",
    "\n",
    "    Args:\n",
    "        X (ndarray): input data(without label)\n",
    "        k (int): the number of cluster\n",
    "\n",
    "    Return:\n",
    "        history (dict): a dictionary that contains \"U\", \"Z\", \"W\", \"cost\" for all time steps of updating. \n",
    "                        it is obvious that the values of last time step is important\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    n_samples = X.shape[0] # Number of samples\n",
    "    n_features = X.shape[1] # Number of features\n",
    "    n_clusters = k # Number of clusters\n",
    "\n",
    "    # Dictionary of history\n",
    "    history = {\n",
    "        'U': [],\n",
    "        'Z': [],\n",
    "        'W': [],\n",
    "        'cost': []\n",
    "\n",
    "        }\n",
    "    # initial centers randomly by choosing from hte dataset randomly\n",
    "    Z_initial_index = np.random.choice(range(n_samples), size=n_clusters,replace=False)\n",
    "    # Centers of clusters of random samples of data, but they can be any random data_points not necessarily in dataset\n",
    "    Z = X[Z_initial_index , : ]\n",
    "    history['Z'].append(Z)\n",
    "    \n",
    "    # Generate random weights that sum up to 1\n",
    "\n",
    "    weights = (1/n_features) * np.ones(n_features).squeeze()\n",
    "    # weights = np.array([1/4, 1/4, 1/4, 1/4])\n",
    "    history['W'].append(weights)\n",
    "    initial_U = np.zeros((X.shape[0], Z.shape[0]))\n",
    "    history['U'].append(initial_U)\n",
    "\n",
    "    # put every thing together to go for a while loop\n",
    "    Z = history['Z'][-1] # the last update of Z\n",
    "    weights = history['W'][-1] # the last update of W\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # P1 --> update U\n",
    "        U = u_calculation(X, Z, weights)\n",
    "        history['U'].append(U)\n",
    "        # update cost\n",
    "        c = fwsa_cost_function(U, Z, weights, X)\n",
    "        history['cost'].append(c)\n",
    "        if (history['U'][-1] == history['U'][-2]).all():\n",
    "            break\n",
    "\n",
    "        #P2 --> update Z     \n",
    "        Z = update_Z(U, Z, X) # new update of Z\n",
    "        history['Z'].append(Z)\n",
    "        # Update cost\n",
    "        c = fwsa_cost_function(U, Z, weights, X)\n",
    "        history['cost'].append(c)\n",
    "    \n",
    "        # P3 --> update  weights\n",
    "        weights = fwsa_weight_update(X, U, Z, weights)\n",
    "        history['W'].append(weights)\n",
    "        #update cost\n",
    "        c = fwsa_cost_function(U, Z, weights, X)\n",
    "        history['cost'].append(c)\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7904583940559767\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from fwsa_utils import clusters_vec\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Access the features (X) and target (y) data\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "n_clusters = 3\n",
    "n_features = X.shape[1]\n",
    "n_samples = X.shape[0]\n",
    "\n",
    "# Normalize Data\n",
    "def normalizer(data):\n",
    "    return (data - np.mean(data,axis=0)) / (np.max(data, axis=0) - np.min(data, axis=0))\n",
    "\n",
    "X_norm = normalizer(X)\n",
    "\n",
    "average_adjusted_rand_score_array = np.zeros(100)\n",
    "for i in range(100):\n",
    "    history = fwsa(X_norm, n_clusters)\n",
    "    U = history[\"U\"][-1]\n",
    "    clusters = clusters_vec(U)\n",
    "    a_r_s = adjusted_rand_score(y, clusters )\n",
    "    average_adjusted_rand_score_array[i] = a_r_s\n",
    "    \n",
    "print(average_adjusted_rand_score_array.mean())\n",
    "\n",
    "# # First Algorithm\n",
    "\n",
    "# average_adjusted_rand_score_array = np.zeros_like(gama_values)\n",
    "\n",
    "# for b, gama in enumerate(gama_values):\n",
    "#     adjusted_rand_score_array = np.zeros(repetition)\n",
    "#     for i in range(repetition):\n",
    "#         history = ewkmeans(X_norm, n_clusters, gama)\n",
    "#         U = history[\"U\"][-1]\n",
    "#         clusters = clusters_vec(U)\n",
    "#         a_r_s = adjusted_rand_score(y, clusters )\n",
    "#         adjusted_rand_score_array[i] = a_r_s\n",
    "\n",
    "#     average_adjusted_rand_score_array[b] =  adjusted_rand_score_array.mean()\n",
    "#     # print(average_adjusted_rand_score_array)\n",
    "#     # print(history[\"cost\"])\n",
    "\n",
    "# # Plot the data\n",
    "# plt.plot(gama_values,average_adjusted_rand_score_array )\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel('gama values')\n",
    "# plt.ylabel(f'Average of Adjusted Rand Score for {repetition} repetition of gama')\n",
    "# plt.title('First Algorithm ')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.5618976128812467,\n",
       " 4.561744439336336,\n",
       " 5.957399193881965,\n",
       " 6.622220254637244,\n",
       " 6.853300054228389,\n",
       " 8.625865771729378,\n",
       " 8.79269634450879,\n",
       " 8.685249782429256,\n",
       " 10.080298034314824,\n",
       " 10.352949538004625,\n",
       " 10.216919864773196,\n",
       " 11.168541712139938,\n",
       " 11.386728865030305,\n",
       " 11.229743469026666,\n",
       " 11.785709279299448,\n",
       " 12.109804604001452,\n",
       " 11.893335568370308,\n",
       " 12.20664469889401,\n",
       " 12.359213548603643,\n",
       " 12.275997740885153,\n",
       " 12.469671325857878,\n",
       " 12.469671325857878]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['cost']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
