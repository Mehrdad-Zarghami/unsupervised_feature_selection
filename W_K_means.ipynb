{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.762523</td>\n",
       "      <td>6.646361</td>\n",
       "      <td>2.997420</td>\n",
       "      <td>4.014394</td>\n",
       "      <td>-10.413807</td>\n",
       "      <td>9.076811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.994561</td>\n",
       "      <td>9.096160</td>\n",
       "      <td>6.954537</td>\n",
       "      <td>0.105904</td>\n",
       "      <td>-6.193367</td>\n",
       "      <td>-8.492825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.355991</td>\n",
       "      <td>7.499439</td>\n",
       "      <td>4.193364</td>\n",
       "      <td>2.829568</td>\n",
       "      <td>-6.665533</td>\n",
       "      <td>-8.125848</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.171629</td>\n",
       "      <td>-5.403025</td>\n",
       "      <td>2.834458</td>\n",
       "      <td>-6.508950</td>\n",
       "      <td>-4.454671</td>\n",
       "      <td>-1.297056</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.077276</td>\n",
       "      <td>6.415959</td>\n",
       "      <td>1.445529</td>\n",
       "      <td>4.916843</td>\n",
       "      <td>-9.087393</td>\n",
       "      <td>8.420642</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>-0.575299</td>\n",
       "      <td>-3.749960</td>\n",
       "      <td>1.270082</td>\n",
       "      <td>-7.257834</td>\n",
       "      <td>-4.160710</td>\n",
       "      <td>-3.831128</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>6.616100</td>\n",
       "      <td>-6.296643</td>\n",
       "      <td>-7.076346</td>\n",
       "      <td>-6.225480</td>\n",
       "      <td>-4.170132</td>\n",
       "      <td>1.999122</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-1.962100</td>\n",
       "      <td>8.812093</td>\n",
       "      <td>4.422198</td>\n",
       "      <td>3.071947</td>\n",
       "      <td>-6.054211</td>\n",
       "      <td>-6.066600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-1.723541</td>\n",
       "      <td>-5.295087</td>\n",
       "      <td>0.942376</td>\n",
       "      <td>-6.049296</td>\n",
       "      <td>-4.624808</td>\n",
       "      <td>-2.326259</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>-7.779903</td>\n",
       "      <td>5.564783</td>\n",
       "      <td>0.839042</td>\n",
       "      <td>2.122219</td>\n",
       "      <td>-9.857717</td>\n",
       "      <td>10.115739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f0        f1        f2        f3         f4         f5  cluster\n",
       "0   -8.762523  6.646361  2.997420  4.014394 -10.413807   9.076811        1\n",
       "1   -2.994561  9.096160  6.954537  0.105904  -6.193367  -8.492825        0\n",
       "2   -3.355991  7.499439  4.193364  2.829568  -6.665533  -8.125848        0\n",
       "3   -0.171629 -5.403025  2.834458 -6.508950  -4.454671  -1.297056        3\n",
       "4   -9.077276  6.415959  1.445529  4.916843  -9.087393   8.420642        1\n",
       "..        ...       ...       ...       ...        ...        ...      ...\n",
       "195 -0.575299 -3.749960  1.270082 -7.257834  -4.160710  -3.831128        3\n",
       "196  6.616100 -6.296643 -7.076346 -6.225480  -4.170132   1.999122        2\n",
       "197 -1.962100  8.812093  4.422198  3.071947  -6.054211  -6.066600        0\n",
       "198 -1.723541 -5.295087  0.942376 -6.049296  -4.624808  -2.326259        3\n",
       "199 -7.779903  5.564783  0.839042  2.122219  -9.857717  10.115739        1\n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# producing clustering dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "n_samples = 200\n",
    "n_features = 6\n",
    "n_clusters = 4\n",
    "# Generate random clustering dataset with 100 samples and 4 centers\n",
    "X, y = make_blobs(n_samples=n_samples, n_features=n_features , centers=n_clusters, random_state=42)\n",
    "\n",
    "\n",
    "df_x = pd.DataFrame(X)\n",
    "df_y = pd.DataFrame(y)\n",
    "df = pd.concat([df_x, df_y], axis=1)\n",
    "df.columns = ['f0', 'f1','f2','f3','f4','f5','cluster']\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of history\n",
    "history = {\n",
    "    'U': [],\n",
    "    'Z': [],\n",
    "    'W': [],\n",
    "    'cost': []\n",
    "\n",
    "    }\n",
    "time_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([136,  28,  16, 142])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial centers randomly by choosing from hte dataset randomly\n",
    "Z_initial_index = np.random.choice(range(n_samples), size=n_clusters)\n",
    "Z_initial_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>-0.043706</td>\n",
       "      <td>-3.977818</td>\n",
       "      <td>4.312319</td>\n",
       "      <td>-7.899311</td>\n",
       "      <td>-2.421143</td>\n",
       "      <td>-2.474852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-8.425396</td>\n",
       "      <td>6.759798</td>\n",
       "      <td>1.200080</td>\n",
       "      <td>4.405139</td>\n",
       "      <td>-9.343344</td>\n",
       "      <td>8.891254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-3.837384</td>\n",
       "      <td>9.211147</td>\n",
       "      <td>5.378345</td>\n",
       "      <td>2.144538</td>\n",
       "      <td>-6.995275</td>\n",
       "      <td>-7.181213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>-8.947088</td>\n",
       "      <td>7.725235</td>\n",
       "      <td>2.712444</td>\n",
       "      <td>3.760231</td>\n",
       "      <td>-9.364218</td>\n",
       "      <td>9.410789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f0        f1        f2        f3        f4        f5\n",
       "136 -0.043706 -3.977818  4.312319 -7.899311 -2.421143 -2.474852\n",
       "28  -8.425396  6.759798  1.200080  4.405139 -9.343344  8.891254\n",
       "16  -3.837384  9.211147  5.378345  2.144538 -6.995275 -7.181213\n",
       "142 -8.947088  7.725235  2.712444  3.760231 -9.364218  9.410789"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Centers of clusters of random samples of data, but they can be any random data_points not necessarily in dataset\n",
    "Z_df = df.iloc[Z_initial_index,:-1]\n",
    "Z_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04370556, -3.97781759,  4.31231877, -7.89931061, -2.42114323,\n",
       "        -2.47485235],\n",
       "       [-8.4253963 ,  6.75979836,  1.20007984,  4.40513877, -9.34334354,\n",
       "         8.89125387],\n",
       "       [-3.83738367,  9.21114736,  5.37834542,  2.14453797, -6.99527547,\n",
       "        -7.18121329],\n",
       "       [-8.94708791,  7.72523464,  2.71244423,  3.76023108, -9.36421763,\n",
       "         9.41078944]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Z_df to ndarray\n",
    "Z = Z_df.to_numpy()\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['Z'].append(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09005344, 0.00320794, 0.25596101, 0.15151899, 0.19957969,\n",
       "       0.29967893])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate random weights that sum up to 1\n",
    "weights = np.random.dirichlet(np.ones(n_features), size=1).squeeze()\n",
    "weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['W'].append(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'U': [],\n",
       " 'Z': [array([[-0.04370556, -3.97781759,  4.31231877, -7.89931061, -2.42114323,\n",
       "          -2.47485235],\n",
       "         [-8.4253963 ,  6.75979836,  1.20007984,  4.40513877, -9.34334354,\n",
       "           8.89125387],\n",
       "         [-3.83738367,  9.21114736,  5.37834542,  2.14453797, -6.99527547,\n",
       "          -7.18121329],\n",
       "         [-8.94708791,  7.72523464,  2.71244423,  3.76023108, -9.36421763,\n",
       "           9.41078944]])],\n",
       " 'W': [array([0.09005344, 0.00320794, 0.25596101, 0.15151899, 0.19957969,\n",
       "         0.29967893])],\n",
       " 'cost': []}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• U is an M × k partition matrix, ui,l is a binary variable, and ui,l = 1 indicates that record i is allocated to cluster l.  \n",
    "• Z = {Z1, Z2, ..., Zk} is a set of k vectors representing the k-cluster centers.  \n",
    "• W = [w1, w2, ..., wN ] is a set of weights.  \n",
    "• d(xi,j, zl,j) is a distance or dissimilarity measure between object i and the center of cluster l on the jth feature."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. P1: Fix Z and W ; solve the reduced problem for U\n",
    "2. P2: Fix U and W ; solve the reduced problem for Z\n",
    "3. P3: Fix U and Z ; solve the reduced problem for W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_distance(s1, s2, weight_vec, beta):\n",
    "    \"\"\"Calculate the weighted distance between two samples s1 and  s2 and based on the weights that each feature has\n",
    "\n",
    "    Args:\n",
    "        s1 (ndarray): _description_\n",
    "        s2 (ndarray): _description_\n",
    "        weight_vec (ndarray): a vector of size (n_features, ), each element is the weight of corresponding feature.\n",
    "        beta (scaler): the power of weights vector\n",
    "\n",
    "    Returns:\n",
    "        scaler: the weighted distance between two samples\n",
    "    \"\"\"\n",
    "    distance_vec = np.square(s1 - s2) # Element_wise --> for each feature\n",
    "    # w**beta\n",
    "    weights_beta_vector = np.power(weight_vec, beta)\n",
    "\n",
    "    weighted_distance = np.dot(distance_vec, weights_beta_vector.T)\n",
    "    return weighted_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.518056841586095"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_distance(Z[0],X[0], weights, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_center(sample, centers, weight_vector, beta=2):\n",
    "    \"\"\"it takes a sample and compare its distance to centers of clusters and return the cluster with closest center.\n",
    "\n",
    "    Args:\n",
    "        sample (ndarray): A vector that represent a data point\n",
    "        centers (ndarray): A ndarray with the shape of (n_clusters, n_features) where each row represent a center of a cluster\n",
    "        weight_vector (ndarray): a vector of wights for corresponding feature\n",
    "        beta (scaler): a bridge that bring\n",
    "    Returns:\n",
    "        int: the number of cluster which is closest to the samples\n",
    "    \"\"\"\n",
    "    d = [] # list of weighted distances\n",
    "    for c in centers:\n",
    "        w_d = weighted_distance(sample, c, weight_vector, beta)\n",
    "        d.append(w_d)\n",
    "    assigned_cluster = np.argmin(d)\n",
    "    return assigned_cluster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_calculation(data, centers, weights, beta = 2):\n",
    "   \"\"\" Calculate U based on Z and W and our dataset\n",
    "   \"\"\"\n",
    "   n_spl = data.shape[0] # umber of samples\n",
    "   n_clu = centers.shape[0] # number of clusters\n",
    "   u_matrix = np.zeros((n_spl, n_clu))\n",
    "   for i, x in enumerate(data):\n",
    "      l = closest_center(x, centers, weights, beta)\n",
    "      u_matrix[i][l] = 1\n",
    "   return u_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = u_calculation(X, Z, weights)\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['U'].append(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters_vec(U):\n",
    "    # a vector of size (n_samples, ) which each element shows the cluster that each samples is assigned to\n",
    "    c_vec = np.zeros(n_samples)\n",
    "    for m, u in enumerate(U):\n",
    "        c_vec[m] = np.argmax(u)\n",
    "    c_vec = c_vec.astype(int)\n",
    "    return c_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, 0, 1, 0, 0, 0, 2, 2, 3, 0, 2, 0, 1, 0, 2, 0, 0, 3, 0, 3,\n",
       "       0, 1, 0, 2, 0, 3, 1, 1, 2, 2, 0, 3, 0, 0, 2, 2, 3, 2, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 3, 2, 3, 0, 0, 0, 0, 3, 1, 1, 3, 0, 0, 3, 2, 2, 3, 0,\n",
       "       0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 1, 0, 3, 0, 3, 0, 0, 0, 0, 1, 0,\n",
       "       0, 2, 2, 1, 0, 2, 0, 3, 3, 2, 0, 0, 2, 0, 1, 0, 0, 0, 1, 2, 0, 0,\n",
       "       0, 1, 0, 0, 0, 2, 2, 2, 0, 0, 3, 0, 1, 1, 0, 2, 2, 3, 0, 0, 0, 0,\n",
       "       0, 2, 1, 0, 0, 0, 0, 0, 3, 2, 3, 0, 2, 0, 2, 2, 2, 2, 0, 3, 0, 2,\n",
       "       3, 0, 0, 0, 1, 0, 1, 2, 0, 2, 0, 0, 3, 2, 2, 2, 0, 0, 0, 0, 2, 3,\n",
       "       0, 1, 2, 2, 1, 2, 0, 3, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2,\n",
       "       0, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_vec(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 100, 1: 24, 2: 50, 3: 26}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_elements, counts = np.unique(clusters_vec(U), return_counts=True)\n",
    "dict(zip(unique_elements, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(U, Z, W, X, beta = 2):\n",
    "    \"\"\"Calculate the cost function\n",
    "\n",
    "    Args:\n",
    "        U (ndarray):  U is an (M, k) matrix, ui,l is a binary variable, and ui,l = 1 indicates that record i is allocated to cluster l.\n",
    "        Z (ndarray): is a set of k vectors representing the k-cluster centers of size (n_clusters, n_features)\n",
    "        W (ndarray): W = [w1, w2, ..., wN ] is a set of weights of size (n_features, )\n",
    "        X (ndarray): matrix of records (n_records, n_features)\n",
    "        beta (int, optional): The power of elements of weights vector Defaults to 2.\n",
    "    \"\"\"\n",
    "    P = 0 # initial value of cost\n",
    "\n",
    "    cl_vec = clusters_vec(U)\n",
    "    \n",
    "    # Updating P\n",
    "    for m, c in enumerate(cl_vec):\n",
    "        w_d = weighted_distance(X[m], Z[c], W, beta)\n",
    "        P += w_d\n",
    "        P =  P.item() # to convert it to a single scaler\n",
    "    return(P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_t = cost_function(U, Z, weights, X, beta = 2)\n",
    "history['cost'].append(c_t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters_dict(U):\n",
    "    # Finding the index of samples in each cluster\n",
    "    n_clusters = U.shape[1]\n",
    "    cluster_dict = {}\n",
    "    clu_vec = clusters_vec(U)\n",
    "\n",
    "    for i in range(n_clusters):\n",
    "        cluster_dict[i] = np.where(clu_vec == i)[0]\n",
    "        \n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z_update = np.zeros_like(Z)\n",
    "# for i,ind in cluster_dict.items():\n",
    "#     Z_update[i] = np.mean(X[ind], axis=0)\n",
    "\n",
    "# Z = Z_update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Z(U, Z, X):\n",
    "    \"\"\"Update Z i.e. the centers of clusters, by taking mean of teh samples in each cluster\n",
    "    \"\"\"\n",
    "    cluster_dict = clusters_dict(U)\n",
    "\n",
    "    new_Z = np.zeros_like(Z)\n",
    "    for i,ind in cluster_dict.items():\n",
    "        new_Z[i] = np.mean(X[ind], axis=0)\n",
    "    \n",
    "    return new_Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Z\n",
    "Z = history['Z'][-1] # the last update of Z\n",
    "weights = history['W'][-1] # the last update of weights\n",
    "\n",
    "Z_t = update_Z(U, Z, X) # new update of Z\n",
    "history['Z'].append(Z_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update cost\n",
    "c_t = cost_function(U, Z_t, weights, X, beta = 2) \n",
    "history['cost'].append(c_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[497.8511571832728, 195.77152687364324]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['cost']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iteration over all features to calculate Dj\n",
    "# U = history['U'][-1] # the lsat update of U\n",
    "# Z = history['Z'][-1] # the lsat update of Z\n",
    "# cluster_dict = clusters_dict(U)\n",
    "\n",
    "# D = []\n",
    "# for j in range(n_features):\n",
    "#     d_j = 0\n",
    "#     for l in range(n_clusters):\n",
    "#         inx_in_cluster = cluster_dict[l]\n",
    "#         # Distance for feature \"j\" in cluster \"l\"\n",
    "#         d_j_l =np.sum(np.square(X[inx_in_cluster][j]-Z[l][j]))\n",
    "#         d_j += d_j_l\n",
    "\n",
    "#     D.append(d_j)\n",
    "\n",
    "# D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dj(X, U, Z):\n",
    "    # Iteration over all features to calculate Dj for each feature\n",
    "    \n",
    "    cluster_dict = clusters_dict(U)\n",
    "    n_features = X.shape[1]\n",
    "    n_clusters = U.shape[1]\n",
    "    \n",
    "    D = []\n",
    "    for j in range(n_features):\n",
    "        d_j = 0\n",
    "        for l in range(n_clusters):\n",
    "            inx_in_cluster = cluster_dict[l]\n",
    "            # Distance for feature \"j\" in cluster \"l\"\n",
    "            d_j_l =np.sum(np.square(X[inx_in_cluster][j]-Z[l][j]))\n",
    "            d_j += d_j_l\n",
    "\n",
    "        D.append(d_j)\n",
    "    return D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2176.22214506837,\n",
       " 2136.2587321721894,\n",
       " 1197.6594521979107,\n",
       " 1127.7122319272262,\n",
       " 2499.7883350746847,\n",
       " 2297.9382109519115]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = history['U'][-1] # the lsat update of U\n",
    "Z = history['Z'][-1] # the lsat update of Z\n",
    "d = dj(X, U, Z)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # weights_update\n",
    "# weights_update = np.zeros_like(weights)\n",
    "# beta = 2\n",
    "\n",
    "# # wherever D is zero, the corresponding weight is zero\n",
    "# ind_D_zero = np.where(D == 0 )[0]\n",
    "# weights_update[ind_D_zero] = 0\n",
    "\n",
    "# ind_D_not_zero = np.where(D)[0]\n",
    "# for j in ind_D_not_zero:\n",
    "#     Dj_Dt = 0\n",
    "    \n",
    "#     for t in ind_D_not_zero:\n",
    "#        Dj_Dt += (D[j] / D[t]) ** (1 / ( beta - 1) )\n",
    "    \n",
    "#     weights_update[j] = 1 / Dj_Dt\n",
    "\n",
    "# weights_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_update(X, U, Z, weights, beta=2):\n",
    "\n",
    "    # D calculation:\n",
    "    D = dj(X, U, Z)\n",
    "\n",
    "    \n",
    "    # weights_update\n",
    "    weights_upd = np.zeros_like(weights)\n",
    "\n",
    "\n",
    "    # wherever D is zero, the corresponding weight is zero\n",
    "    ind_D_zero = np.where(D == 0 )[0] # indexes of zero Dj\n",
    "    weights_upd[ind_D_zero] = 0\n",
    "\n",
    "    # D is not zero\n",
    "    ind_D_not_zero = np.where(D)[0] ## indexes of non-zero Dj\n",
    "    for j in ind_D_not_zero:\n",
    "        \n",
    "        Dj_Dt = 0\n",
    "        for t in ind_D_not_zero:\n",
    "            Dj_Dt += (D[j] / D[t]) ** (1 / ( beta - 1) )\n",
    "        \n",
    "        weights_upd[j] = 1 / Dj_Dt\n",
    "\n",
    "    return weights_upd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_t = cost_function(U, Z, weights_update, X, beta = 2)\n",
    "# c_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = history['U'][-1] # the lsat update of U\n",
    "Z = history['Z'][-1] # the lsat update of Z\n",
    "weights_t = weight_update(X, U, Z, weights, beta=2)\n",
    "history['W'].append(weights_t)\n",
    "c_t = cost_function(U, Z, weights_t, X, beta = 2)\n",
    "history['cost'].append(c_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[497.8511571832728, 195.77152687364324, 172.88227678121527]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do it in a loop \n",
    "# keep track of changes for weights "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put everything together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final vector of weights is:\n",
      " [0.13180226 0.13432983 0.2394493  0.25484279 0.11477661 0.12479922] \n"
     ]
    }
   ],
   "source": [
    "cost_difference = []\n",
    "\n",
    "while True:\n",
    "    cost_difference = np.abs(history['cost'][-1] - history['cost'][-2])\n",
    "    if  cost_difference > 0.0001:\n",
    "\n",
    "        # P1 --> update U\n",
    "        Z = history['Z'][-1] # the last update of Z\n",
    "        weights = history['W'][-1] # the last update of W\n",
    "        U = u_calculation(X, Z, weights)\n",
    "        history['U'].append(U)\n",
    "        U = history['U'][-1]\n",
    "        # update cost\n",
    "        c_t = cost_function(U, Z, weights, X, beta = 2)\n",
    "        history['cost'].append(c_t)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "    #P2 --> update Z\n",
    "    cost_difference = np.abs(history['cost'][-1] - history['cost'][-2])\n",
    "    if  cost_difference > 0.0001:\n",
    "        U = history['U'][-1] # the last update of U\n",
    "        Z = history['Z'][-1] # the last update of Z\n",
    "        weights = history['W'][-1] # the last update of weights\n",
    "\n",
    "        Z_t = update_Z(U, Z, X) # new update of Z\n",
    "        history['Z'].append(Z_t)\n",
    "        # Update cost\n",
    "        c_t = cost_function(U, Z_t, weights, X, beta = 2) \n",
    "        history['cost'].append(c_t)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "    # P3 --> update  weights\n",
    "    cost_difference = np.abs(history['cost'][-1] - history['cost'][-2])\n",
    "    if  cost_difference > 0.0001:\n",
    "        U = history['U'][-1] # the lsat update of U\n",
    "        Z = history['Z'][-1] # the lsat update of Z\n",
    "        weights_t = weight_update(X, U, Z, weights, beta=2)\n",
    "        history['W'].append(weights_t)\n",
    "        #update cost\n",
    "        c_t = cost_function(U, Z, weights_t, X, beta = 2)\n",
    "        history['cost'].append(c_t)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "final_weights = history['W'][-1]\n",
    "print(f'Final vector of weights is:\\n {final_weights} ')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[497.8511571832728,\n",
       " 195.77152687364324,\n",
       " 172.88227678121527,\n",
       " 172.7946333028405,\n",
       " 172.7313916622659,\n",
       " 172.6104067616244,\n",
       " 172.55486852243962,\n",
       " 172.53210560797106,\n",
       " 172.5821839502257,\n",
       " 172.57912453320384,\n",
       " 172.56269498879087,\n",
       " 172.47716870921377,\n",
       " 172.47716870921377]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(history['W'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.48822922e-05 8.09846973e-02 7.04670087e-02 8.48523412e-01]]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_rows = 3\n",
    "num_columns = 4\n",
    "\n",
    "matrix = np.random.dirichlet(np.ones(num_columns), size=1)\n",
    "\n",
    "print(matrix)\n",
    "print(np.sum(matrix, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsupervised",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
